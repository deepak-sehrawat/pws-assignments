{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol 1\n",
    "\n",
    "# Polynomial functions and kernel functions are both used in machine learning, particularly in the context of support vector machines (SVMs) and kernel methods, to transform data into higher-dimensional feature spaces. However, they serve different purposes and have distinct relationships:\n",
    "\n",
    "# Polynomial Functions:\n",
    "\n",
    "    # Polynomial functions are a class of mathematical functions that involve variables raised to integer powers, like x^2, x^3, etc. In machine learning, polynomial features are used to create new features from the existing ones by raising them to different powers. This can help capture more complex relationships between features and improve the performance of certain algorithms.\n",
    "\n",
    "# Kernel Functions:\n",
    "\n",
    "    # Kernel functions are used in the context of kernel methods, such as the kernel trick in SVMs. They are a way to implicitly map data into a higher-dimensional feature space without explicitly computing the transformed feature vectors. The kernel function calculates the similarity or dot product between data points in this higher-dimensional space.\n",
    "\n",
    "# The relationship between polynomial functions and kernel functions in machine learning lies in the fact that some kernel functions are based on polynomial transformations. The polynomial kernel is a specific type of kernel function that uses polynomial functions to implicitly map data into a higher-dimensional space. The polynomial kernel has the following form:\n",
    "\n",
    "    # K(x, y) = (α * x * y + c)^d\n",
    "\n",
    "# Here, 'x' and 'y' are the input data points, 'd' is the degree of the polynomial, 'c' is a constant, and 'α' is a scaling factor. The polynomial kernel effectively captures interactions between features up to a certain degree 'd', allowing SVMs to model non-linear decision boundaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sol 2\n",
    "\n",
    "# we can implement a Support Vector Machine (SVM) with a polynomial kernel in Python using Scikit-learn, a popular machine learning library. Here's a step-by-step guide on how to do it:\n",
    "\n",
    "# 1. Import the necessary libraries:\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 2. Load or create our dataset. For this example, let's use the Iris dataset as an illustration:\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 3. Split the dataset into training and testing sets:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 4. Create an SVM classifier with a polynomial kernel:\n",
    "\n",
    "# Create an SVM classifier with a polynomial kernel\n",
    "svm_classifier = SVC(kernel='poly', degree=3)  # 'poly' indicates a polynomial kernel, and we can set the 'degree' parameter as needed\n",
    "\n",
    "    # In the above code, 'degree' specifies the degree of the polynomial kernel. we can adjust it based on our problem's complexity.\n",
    "\n",
    "# 5. Train the SVM classifier on the training data:\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 6. Make predictions on the test data:\n",
    "\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# 7. Evaluate the classifier's performance using metrics like accuracy, precision, recall, etc.:\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# # # That's it! we've now implemented an SVM classifier with a polynomial kernel using Scikit-learn. Make sure to tune hyperparameters like the degree of the polynomial kernel and regularization parameters (e.g., C) to achieve the best performance on our specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol 3\n",
    "\n",
    "# In Support Vector Regression (SVR), epsilon  is a hyperparameter that determines the width of the epsilon-tube around the regression line. The epsilon-tube is a margin within which errors are tolerated, and data points that fall outside this tube are considered support vectors. The width of the epsilon-tube controls the trade-off between the model's accuracy and the number of support vectors.\n",
    "\n",
    "# Here's how increasing the value of epsilon affects the number of support vectors in SVR:\n",
    "\n",
    "# Smaller Epsilon : \n",
    "    # When epsilon is set to a small value, the epsilon-tube becomes narrow, and the SVR model aims to fit the training data as closely as possible. This results in a smaller margin for error, and the model may capture a larger number of data points within the tube. As a consequence, there might be more support vectors.\n",
    "\n",
    "# Larger Epsilon (ε): \n",
    "    # Increasing the value of epsilon makes the epsilon-tube wider. The SVR model becomes more tolerant of errors and allows data points to fall further from the regression line while still being considered correctly predicted. This results in a larger margin for error, and fewer data points may fall outside the epsilon-tube. Consequently, a larger epsilon typically leads to a smaller number of support vectors.\n",
    "\n",
    "# A larger epsilon makes the SVR model more tolerant of errors and results in a smaller number of support vectors. Conversely, a smaller epsilon tightens the tolerance for errors and may lead to a larger number of support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sol 4\n",
    "\n",
    "Support Vector Regression (SVR) is a powerful regression technique in machine learning, and its performance is significantly influenced by several hyperparameters, including the choice of kernel function, C parameter, epsilon parameter (ε), and gamma parameter ). Let's discuss how each of these parameters works and provide examples of when we might want to increase or decrease their values:\n",
    "\n",
    "1. Choice of Kernel Function:\n",
    "   - Linear Kernel: The linear kernel assumes a linear relationship between input features and the target variable. Use this when we believe the data has a linear relationship.\n",
    "   - Polynomial Kernel: The polynomial kernel captures non-linear relationships up to a certain degree specified by the 'degree' parameter. Increase the degree for more complex relationships.\n",
    "   - Radial Basis Function (RBF) Kernel: The RBF kernel models non-linear relationships by considering data points in a higher-dimensional space. Increase 'gamma' for a more flexible model.\n",
    "   - Custom Kernels: we can also define custom kernel functions tailored to our specific problem.\n",
    "\n",
    "   Example: If we suspect that our data has a complex, non-linear relationship, we may choose an RBF kernel with a higher gamma value to allow the model to capture more intricate patterns in the data.\n",
    "\n",
    "2. C Parameter:\n",
    "   - The C parameter controls the trade-off between minimizing the training error and minimizing the model's complexity (smoothness). A small C value allows for a larger margin but may tolerate more training errors, while a large C value enforces a smaller margin but aims to minimize training errors.\n",
    "\n",
    "   Example: If we have noisy data or we suspect that overfitting is occurring, we might decrease the C parameter to encourage a larger margin and prevent the model from fitting the noise.\n",
    "\n",
    "3. Epsilon Parameter (ε):\n",
    "   - Epsilon defines the width of the epsilon-tube around the regression line. It determines how tolerant the model is to errors. Smaller ε values make the model less tolerant, while larger ε values allow more tolerance for errors.\n",
    "\n",
    "   Example: If we want to fit the training data closely and minimize prediction errors, we might choose a smaller ε. On the other hand, if we want the model to be more robust to outliers or noisy data, we can increase ε.\n",
    "\n",
    "4. Gamma Parameter:\n",
    "   - In the context of the RBF kernel, gamma controls the shape and flexibility of the decision boundary. A smaller results in a more flexible boundary, while a larger makes the boundary more rigid.\n",
    "\n",
    "   Example: If our data is highly variable or noisy, we may decrease to make the model more robust and avoid overfitting. If our data is well-behaved and we want a tighter fit, we can increase.\n",
    "\n",
    "NOTE-the choice of these parameters depends on the specific characteristics of our dataset and the trade-off between model complexity and performance.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sol 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports & make dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "x=pd.DataFrame(load_breast_cancer().data,columns=load_breast_cancer().feature_names)\n",
    "y=load_breast_cancer().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, X_test, y_train, Y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is not much necessary to do the scaling of our data set regions are:\n",
    "    # 1. not a big dataset \n",
    "    # 2. in classification we mainly not do the scaling for small datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training model\n",
    "from sklearn.svm import SVC\n",
    "SVC_classifier=SVC()\n",
    "SVC_classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "y_pred=SVC_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score= 0.9521276595744681\n",
      "precision_score= 0.9375\n",
      "recall_score= 0.9917355371900827\n",
      "f1_score= 0.963855421686747\n",
      "classification_report=\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93        67\n",
      "           1       0.94      0.99      0.96       121\n",
      "\n",
      "    accuracy                           0.95       188\n",
      "   macro avg       0.96      0.94      0.95       188\n",
      "weighted avg       0.95      0.95      0.95       188\n",
      "\n",
      "confusion_matrix=\n",
      " [[ 59   8]\n",
      " [  1 120]]\n"
     ]
    }
   ],
   "source": [
    "# all scoring check\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,precision_score,recall_score,f1_score\n",
    "print(\"accuracy_score=\",accuracy_score(Y_test,y_pred))\n",
    "print(\"precision_score=\",precision_score(Y_test,y_pred))\n",
    "print(\"recall_score=\",recall_score(Y_test,y_pred))\n",
    "print(\"f1_score=\",f1_score(Y_test,y_pred))\n",
    "print(\"classification_report=\\n\",classification_report(Y_test,y_pred))\n",
    "print(\"confusion_matrix=\\n\",confusion_matrix(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n",
      "[CV 1/2] END ........C=0.1, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ........C=0.1, gamma=1, kernel=rbf;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END .......C=0.1, gamma=1, kernel=poly;, score=0.937 total time=   1.8s\n",
      "[CV 2/2] END .......C=0.1, gamma=1, kernel=poly;, score=0.937 total time=  10.8s\n",
      "[CV 1/2] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.953 total time=   3.4s\n",
      "[CV 2/2] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.921 total time=   5.2s\n",
      "[CV 1/2] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.958 total time=   7.7s\n",
      "[CV 2/2] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.926 total time=  14.9s\n",
      "[CV 1/2] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.942 total time=   3.6s\n",
      "[CV 2/2] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.932 total time=   6.9s\n",
      "[CV 1/2] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END ..........C=1, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ..........C=1, gamma=1, kernel=rbf;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END .........C=1, gamma=1, kernel=poly;, score=0.937 total time=   1.8s\n",
      "[CV 2/2] END .........C=1, gamma=1, kernel=poly;, score=0.937 total time=  10.8s\n",
      "[CV 1/2] END ......C=1, gamma=1, kernel=sigmoid;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ......C=1, gamma=1, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END ........C=1, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ........C=1, gamma=0.1, kernel=rbf;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END .......C=1, gamma=0.1, kernel=poly;, score=0.953 total time=   3.4s\n",
      "[CV 2/2] END .......C=1, gamma=0.1, kernel=poly;, score=0.921 total time=   5.2s\n",
      "[CV 1/2] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END .......C=1, gamma=0.01, kernel=rbf;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END .......C=1, gamma=0.01, kernel=rbf;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END ......C=1, gamma=0.01, kernel=poly;, score=0.958 total time=   7.7s\n",
      "[CV 2/2] END ......C=1, gamma=0.01, kernel=poly;, score=0.926 total time=  14.7s\n",
      "[CV 1/2] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END ......C=1, gamma=0.001, kernel=rbf;, score=0.927 total time=   0.0s\n",
      "[CV 2/2] END ......C=1, gamma=0.001, kernel=rbf;, score=0.884 total time=   0.0s\n",
      "[CV 1/2] END .....C=1, gamma=0.001, kernel=poly;, score=0.942 total time=   3.6s\n",
      "[CV 2/2] END .....C=1, gamma=0.001, kernel=poly;, score=0.932 total time=   6.9s\n",
      "[CV 1/2] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END .........C=10, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END .........C=10, gamma=1, kernel=rbf;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END ........C=10, gamma=1, kernel=poly;, score=0.937 total time=   1.8s\n",
      "[CV 2/2] END ........C=10, gamma=1, kernel=poly;, score=0.937 total time=  10.8s\n",
      "[CV 1/2] END .....C=10, gamma=1, kernel=sigmoid;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END .....C=10, gamma=1, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END .......C=10, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END .......C=10, gamma=0.1, kernel=rbf;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END ......C=10, gamma=0.1, kernel=poly;, score=0.953 total time=   3.4s\n",
      "[CV 2/2] END ......C=10, gamma=0.1, kernel=poly;, score=0.921 total time=   5.2s\n",
      "[CV 1/2] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END ......C=10, gamma=0.01, kernel=rbf;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ......C=10, gamma=0.01, kernel=rbf;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END .....C=10, gamma=0.01, kernel=poly;, score=0.958 total time=   7.7s\n",
      "[CV 2/2] END .....C=10, gamma=0.01, kernel=poly;, score=0.926 total time=  14.7s\n",
      "[CV 1/2] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END .....C=10, gamma=0.001, kernel=rbf;, score=0.921 total time=   0.0s\n",
      "[CV 2/2] END .....C=10, gamma=0.001, kernel=rbf;, score=0.858 total time=   0.0s\n",
      "[CV 1/2] END ....C=10, gamma=0.001, kernel=poly;, score=0.942 total time=   3.6s\n",
      "[CV 2/2] END ....C=10, gamma=0.001, kernel=poly;, score=0.932 total time=   6.9s\n",
      "[CV 1/2] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END ........C=100, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ........C=100, gamma=1, kernel=rbf;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END .......C=100, gamma=1, kernel=poly;, score=0.937 total time=   1.8s\n",
      "[CV 2/2] END .......C=100, gamma=1, kernel=poly;, score=0.937 total time=  10.9s\n",
      "[CV 1/2] END ....C=100, gamma=1, kernel=sigmoid;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ....C=100, gamma=1, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END ......C=100, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ......C=100, gamma=0.1, kernel=rbf;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END .....C=100, gamma=0.1, kernel=poly;, score=0.953 total time=   3.4s\n",
      "[CV 2/2] END .....C=100, gamma=0.1, kernel=poly;, score=0.921 total time=   5.3s\n",
      "[CV 1/2] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END .....C=100, gamma=0.01, kernel=rbf;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END .....C=100, gamma=0.01, kernel=rbf;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END ....C=100, gamma=0.01, kernel=poly;, score=0.958 total time=   7.7s\n",
      "[CV 2/2] END ....C=100, gamma=0.01, kernel=poly;, score=0.926 total time=  14.6s\n",
      "[CV 1/2] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 1/2] END ....C=100, gamma=0.001, kernel=rbf;, score=0.921 total time=   0.0s\n",
      "[CV 2/2] END ....C=100, gamma=0.001, kernel=rbf;, score=0.858 total time=   0.0s\n",
      "[CV 1/2] END ...C=100, gamma=0.001, kernel=poly;, score=0.942 total time=   3.6s\n",
      "[CV 2/2] END ...C=100, gamma=0.001, kernel=poly;, score=0.932 total time=   6.9s\n",
      "[CV 1/2] END C=100, gamma=0.001, kernel=sigmoid;, score=0.618 total time=   0.0s\n",
      "[CV 2/2] END C=100, gamma=0.001, kernel=sigmoid;, score=0.621 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['rbf', 'poly', 'sigmoid']},\n",
       "             scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hyperparameters tuning\n",
    "\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "cls=GridSearchCV(SVC(),param_grid,cv=2,verbose=5,scoring=\"accuracy\",refit=True)\n",
    "cls.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, gamma=0.01, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1, gamma=0.01, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1, gamma=0.01, kernel='poly')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.best_estimator_ ## new parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score= 0.9627659574468085\n",
      "precision_score= 0.9830508474576272\n",
      "recall_score= 0.9586776859504132\n",
      "f1_score= 0.9707112970711298\n",
      "classification_report=\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.98      0.96      0.97       121\n",
      "\n",
      "    accuracy                           0.96       188\n",
      "   macro avg       0.96      0.96      0.96       188\n",
      "weighted avg       0.96      0.96      0.96       188\n",
      "\n",
      "confusion_matrix=\n",
      " [[ 65   2]\n",
      " [  5 116]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=cls.predict(X_test)\n",
    "# all scoring check\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,precision_score,recall_score,f1_score\n",
    "print(\"accuracy_score=\",accuracy_score(Y_test,y_pred))\n",
    "print(\"precision_score=\",precision_score(Y_test,y_pred))\n",
    "print(\"recall_score=\",recall_score(Y_test,y_pred))\n",
    "print(\"f1_score=\",f1_score(Y_test,y_pred))\n",
    "print(\"classification_report=\\n\",classification_report(Y_test,y_pred))\n",
    "print(\"confusion_matrix=\\n\",confusion_matrix(Y_test,y_pred))\n",
    "\n",
    "## after the hyperparameter tuning our mode performance is get increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, gamma=0.01, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1, gamma=0.01, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1, gamma=0.01, kernel='poly')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train for the complete dataset\n",
    "final_model=cls.best_estimator_\n",
    "final_model.fit(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving the model\n",
    "import pickle\n",
    "pickle.dump(final_model,open(\"model_for_breast_cancer_SVC_SVM.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9680851063829787"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##try to load and predict for  data\n",
    "import pickle\n",
    "final_model=pickle.load(open(\"model_for_breast_cancer_SVC_SVM.pkl\",\"rb\"))\n",
    "y_pred2=final_model.predict(X_test)\n",
    "accuracy_score(Y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
