{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing of the important libraies \n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  sol 1\n",
    "\n",
    "# ANOVA is a statistical test used to compare means between three or more groups. \n",
    "# Here are the assumptions for ANOVA, with examples of violations that could impact the validity of the results:\n",
    "\n",
    "# Assumption 1: \n",
    "    # Independence: The observations within each group must be independent of each other. This means that the values in one group should not be related to the values in another group.\n",
    "\n",
    "    # Violation Example: In a study examining the effect of a new teaching method on students' test scores, if students within the same class were taught using different methods and their scores were compared, the independence assumption would be violated because the scores of students in the same class are likely to be correlated.\n",
    "\n",
    "# Assumption 2: \n",
    "    # Normality: The residuals (differences between observed values and predicted values) for each group should be normally distributed. This means that the distribution of residuals within each group should resemble a bell-shaped curve.\n",
    "\n",
    "    # Violation Example: If the residuals for one or more groups exhibit a skewed or non-normal distribution, it can affect the validity of ANOVA results. For instance, if the residuals are heavily skewed to the right, it may lead to incorrect conclusions.\n",
    "\n",
    "# Assumption 3: \n",
    "    # Random Sampling: Ideally, the samples should be selected randomly from the population of interest. Random sampling helps ensure that the sample is representative of the population.\n",
    "\n",
    "    # Violation Example: If the sample is not selected randomly and is biased in some way (e.g., convenience sampling), it may not accurately represent the population, potentially leading to biased ANOVA results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol 2\n",
    "\n",
    "# The are three types of ANOVA :\n",
    "\n",
    "# One-Way ANOVA: This type of ANOVA is used when you have one independent variable (factor) and want to compare the means of three or more groups to determine if there are statistically significant differences between those groups. For example, you might use a one-way ANOVA to compare the test scores of students who received different types of tutoring (group A, group B, and group C).\n",
    "\n",
    "# Two-Way ANOVA: Two-way ANOVA is employed when you have two independent variables (factors) and want to examine how they interact to affect a dependent variable. It is suitable for situations where you want to study the effects of two factors simultaneously. For instance, you might use a two-way ANOVA to investigate the impact of both temperature (factor A) and humidity (factor B) on plant growth.\n",
    "\n",
    "# Repeated Measures ANOVA: Repeated measures ANOVA is used when you have a within-subjects design, where the same subjects are measured or tested under different conditions or at multiple time points. This type of ANOVA helps analyze changes in a dependent variable over repeated measurements. For example, you might use repeated measures ANOVA to assess how the performance of individuals (e.g., reaction time) changes under various drug dosages (repeated measurements) over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol 3\n",
    "# The partitioning of variance in Analysis of Variance (ANOVA) refers to the division of the total variation in the data into different components or sources of variation. \n",
    "# Understanding this concept is crucial because it helps researchers identify the factors or sources that contribute to the observed variation in the dependent variable\n",
    "\n",
    "#  understanding the partitioning of variance in ANOVA is fundamental for interpreting and drawing valid conclusions from the analysis. It helps researchers dissect the sources of variation in their data and determine the significance of group differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the SST is = 108.95238095238093478656\n",
      "the SSE is = 10.286\n",
      "the SSR is = 98.667\n"
     ]
    }
   ],
   "source": [
    "# sol 4\n",
    "\n",
    "# Calculate SST (Total Sum of Squares): SST represents the total variability in the data. To calculate it, subtract the grand mean from each individual data point, square the differences, and sum them all.\n",
    "\n",
    "# Calculate SSE (Explained Sum of Squares): SSE represents the variability explained by the group means. Calculate the mean within each group and subtract it from the individual values within that group, square the differences, and sum them all for each group. Then, sum up these values for all groups.\n",
    "\n",
    "# Calculate SSR (Residual Sum of Squares): SSR represents the unexplained variability. It can be calculated by subtracting SSE from SST.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "x1=[9,8,7,8,8,9,8]\n",
    "x2=[7,6,6,7,8,7,6]\n",
    "x3=[4,3,2,3,4,3,2]\n",
    "data_array=np.array([x1,x2,x3])\n",
    "groups=[x1,x2,x3]\n",
    "\n",
    "# Calculate SST\n",
    "grand_mean = np.mean(data_array)\n",
    "sst = np.sum((data_array - grand_mean)**2)\n",
    "print(f\"the SST is = {sst:.23}\")\n",
    "\n",
    "# Calculate SSE and SSR (assuming you have groups)\n",
    "group_means = [np.mean(group) for group in groups]\n",
    "sse = np.sum([(group - group_mean)**2 for group, group_mean in zip(groups, group_means)])\n",
    "print(f\"the SSE is = {sse:.3f}\")\n",
    "ssr = sst - sse\n",
    "print(f\"the SSR is = {ssr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.0-cp39-cp39-macosx_11_0_arm64.whl (9.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.4 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy!=1.9.2,>=1.4 in /Users/Designer/Library/Python/3.9/lib/python/site-packages (from statsmodels) (1.11.2)\n",
      "Collecting patsy>=0.5.2\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[K     |████████████████████████████████| 233 kB 30.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.0 in /Users/Designer/Library/Python/3.9/lib/python/site-packages (from statsmodels) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.18 in /Users/Designer/Library/Python/3.9/lib/python/site-packages (from statsmodels) (1.25.2)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/Designer/Library/Python/3.9/lib/python/site-packages (from statsmodels) (23.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/Designer/Library/Python/3.9/lib/python/site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/Designer/Library/Python/3.9/lib/python/site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/Designer/Library/Python/3.9/lib/python/site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from patsy>=0.5.2->statsmodels) (1.15.0)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.3 statsmodels-0.14.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 sum_sq   df             F    PR(>F)\n",
      "C(A)       8.000000e+00  1.0  1.600000e+00  0.274577\n",
      "C(B)       9.800000e+01  1.0  1.960000e+01  0.011447\n",
      "C(A):C(B)  1.577722e-30  1.0  3.155444e-31  1.000000\n",
      "Residual   2.000000e+01  4.0           NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# sol 5\n",
    "# To calculate the main effects and interaction effects in a two-way ANOVA using Python, you can use the `scipy.stats` library to perform the analysis of variance. Here's a step-by-step guide on how to do it:\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "\n",
    "# Load Your Data\n",
    "\n",
    "#    You should have your data in a structured format. Let's assume you have a DataFrame `df` with two categorical variables (`factor1` and `factor2`) and a dependent variable (`response`).\n",
    "\n",
    "  \n",
    "# df = pd.read_excel(\"your_data.xlsx\")  # Adjust the file path and format as needed\n",
    "data = {\n",
    "    'A': ['A1', 'A2', 'A1', 'A2', 'A1', 'A2', 'A1', 'A2'],\n",
    "    'B': ['B1', 'B1', 'B2', 'B2', 'B1', 'B1', 'B2', 'B2'],\n",
    "    'Y': [10, 12, 14, 16, 8, 10, 18, 20]\n",
    "}\n",
    "# df =pd.DataFrame([\"Diet A\",[2, 3, 4, 2, 3],[4, 5, 6, 5, 6]],[\"Diet B\",[1, 2, 2, 1, 3],[5, 7, 8, 6, 9]])\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# 3. Fit a Linear Model:\n",
    "\n",
    "#    You can use the `ols` function from `statsmodels` to fit a linear model and perform the ANOVA.\n",
    "\n",
    "# Fit a two-way ANOVA model\n",
    "formula = 'Y ~ C(A) + C(B) + C(A):C(B)'\n",
    "model = ols(formula, df).fit()\n",
    "\n",
    "# 4. Perform ANOVA:\n",
    "\n",
    "#    You can now perform the ANOVA using the `anova_lm` function:\n",
    "\n",
    " \n",
    "anova_table = anova_lm(model, typ=2)\n",
    "   \n",
    "\n",
    "#    The `typ=2` argument specifies the type 2 sum of squares, which is commonly used in two-way ANOVA.\n",
    "\n",
    "# 5. Interpret the Results:\n",
    "\n",
    "#    The `anova_table` contains the p-values for the main effects and interaction effect. You can use these p-values to determine if the effects are statistically significant. Smaller p-values indicate more significant effects.\n",
    "\n",
    "# For example, if the p-value for `C(factor1)` is less than your chosen significance level (e.g., 0.05), you would conclude that there is a significant main effect of `factor1`.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Load your data into a DataFrame\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "# Fit a linear model and perform ANOVA\n",
    "\n",
    "formula = 'Y ~ C(A) + C(B) + C(A):C(B)'\n",
    "model = ols(formula, df).fit()\n",
    "\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "\n",
    "# Interpret the results\n",
    "print(anova_table)\n",
    "\n",
    "# This code will give you the main effects and interaction effects and their associated p-values from a two-way ANOVA using Python. You can adjust the significance level and post-hoc tests if needed for your specific analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol 06\n",
    "# In a one-way ANOVA, the F-statistic and p-value are used to assess whether there are statistically significant differences between the means of three or more groups. Let's interpret the results\n",
    "\n",
    "# 1. F-Statistic:\n",
    "#  The F-statistic in this case is 5.23.\n",
    "# 2. P-Value:\n",
    "#  The p-value is 0.02.\n",
    "\n",
    "# Here's how to interpret these results:\n",
    "\n",
    "# - Null Hypothesis (H0):\n",
    "#  The null hypothesis in a one-way ANOVA assumes that there are no significant differences between the group means. In other words, it assumes that all group means are equal.\n",
    "\n",
    "# - Alternative Hypothesis (Ha):\n",
    "#  The alternative hypothesis suggests that there are significant differences between at least two group means.\n",
    "\n",
    "\n",
    "# Now, let's interpret the results based on the F-statistic and p-value:\n",
    "\n",
    "\n",
    "# 1. F-Statistic:\n",
    "#  The F-statistic is a measure of the variation between group means relative to the variation within the groups. A larger F-statistic indicates greater variation between the groups. In your case, the F-statistic is 5.23, which suggests that there is some degree of difference between the group means.\n",
    "\n",
    "# 2. P-Value:\n",
    "#  The p-value indicates the probability of obtaining the observed F-statistic (or a more extreme one) if the null hypothesis were true. A smaller p-value indicates stronger evidence against the null hypothesis. In your case, the p-value is 0.02, which is less than the typical significance level of 0.05.\n",
    "\n",
    "# Interpretation:\n",
    "\n",
    "\n",
    "# With an F-statistic of 5.23 and a p-value of 0.02, you would typically conclude the following:\n",
    "\n",
    "# - Reject the Null Hypothesis:\n",
    "# Since the p-value (0.02) is less than the significance level (e.g., 0.05), you would reject the null hypothesis. This means that there is strong evidence to suggest that there are statistically significant differences between at least two of the group means.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sol 7\n",
    "# In a repeated measures ANOVA, handling missing data is crucial for ensuring the accuracy and reliability of the analysis. There are several methods to deal with missing data, each with its potential consequences:\n",
    "\n",
    "# Listwise Deletion (Complete Case Analysis): \n",
    "    # This method involves removing cases with missing data. While it simplifies analysis, it reduces sample size, potentially reducing statistical power. Moreover, it may introduce bias if data is not missing completely at random.\n",
    "\n",
    "# Imputation: \n",
    "    # Imputing missing values with estimated values (e.g., mean, median, regression-based imputation) can preserve sample size and power. However, it may introduce bias if the imputed values are inaccurate or if missingness is not random.\n",
    "\n",
    "# Mixed-Model Analysis: \n",
    "    # Using mixed-effects models can directly incorporate missing data, preserving sample size and accounting for correlations within subjects. This method is suitable for missing at random scenarios, but it requires more complex modeling.\n",
    "\n",
    "# The choice depends on the nature of missingness and research goals. Imputation and mixed-models are often preferred for their ability to retain data and handle correlated repeated measures. Regardless of the method, transparent reporting of handling procedures is essential to ensure the validity of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol 8\n",
    "# Common post-hoc tests used after performing an analysis of variance (ANOVA) include Tukey's Honestly Significant Difference (HSD) test, Bonferroni correction, Scheffé's test, and Dunnett's test, among others. These tests are used to make pairwise comparisons between groups when a significant difference is found in the ANOVA. Here's when you might use each one:\n",
    "\n",
    "# Tukey's Honestly Significant Difference (HSD) Test:\n",
    "\n",
    "# When to Use: Tukey's HSD is used when you have conducted an ANOVA and want to compare all pairs of group means to identify which specific groups are significantly different from each other.\n",
    "# Example: In a drug study with multiple treatment groups, Tukey's HSD can help identify which pairs of treatments lead to significantly different outcomes.\n",
    "\n",
    "# Bonferroni Correction:\n",
    "\n",
    "# When to Use: Bonferroni correction is used to control the familywise error rate when conducting multiple pairwise comparisons after ANOVA.\n",
    "# Example: In a genetics study with multiple genetic markers, Bonferroni correction can help ensure that the overall Type I error rate remains low when comparing the effects of each marker on an outcome.\n",
    "\n",
    "# Scheffé's Test:\n",
    "\n",
    "# When to Use: Scheffé's test is a more conservative post-hoc test used when the assumptions of other tests (such as Tukey's) are not met, particularly when sample sizes are unequal.\n",
    "# Example: In an educational study with groups of different sizes, Scheffé's test can be used to compare group means without making distributional assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 13.673957575884488\n",
      "P-value: 3.57842860807437e-06\n",
      "There is significant evidence to reject the null hypothesis.\n",
      "There are significant differences between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "# sol 9\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(102)\n",
    "\n",
    "# let the sample data to perform the one way ANOVA\n",
    "diet_a=np.random.normal(loc=0,scale=1,size=50).round(2)\n",
    "diet_b=np.random.normal(loc=0,scale=1,size=50).round(2)\n",
    "diet_c=np.random.normal(loc=1,scale=2,size=50).round(2)\n",
    "\n",
    "# let the Hypotistesis \n",
    "h0=\"There may not be significant differences between the mean weight loss of the three diets.\"\n",
    "h1=\"There are significant differences between the mean weight loss of the three diets.\"\n",
    "\n",
    "data = {\n",
    "    'Diet_A': diet_a,\n",
    "    'Diet_B': diet_b,\n",
    "    'Diet_C': diet_c\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(df['Diet_A'], df['Diet_B'], df['Diet_C'])\n",
    "\n",
    "\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # let the significance level\n",
    "if p_value < alpha:\n",
    "    print(\"There is significant evidence to reject the null hypothesis.\")\n",
    "    print(h1)\n",
    "else:\n",
    "    print(\"There is not enough evidence to reject the null hypothesis.\")\n",
    "    print(h0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: -2.800386340930907\n",
      "P-Value: 0.0061492414386258454\n",
      "There is a significant difference in test scores between the two groups.\n",
      "\n",
      "\n",
      "A post-hoc test\n",
      "\n",
      "\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "Control Experimental     3.38 0.0061 0.9848 5.7752   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# sol 11\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# let the sample data\n",
    "np.random.seed(100)\n",
    "control_group_scores = np.random.randint(70,92,size=50)\n",
    "experimental_group_scores = np.random.randint(75,94,size=50)\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group_scores, experimental_group_scores)\n",
    "\n",
    "alpha = 0.05  # Let the significance level\n",
    "print(f\"T-Statistic: {t_statistic}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference in test scores between the two groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between the two groups.\")\n",
    "\n",
    "\n",
    "\n",
    "# a post-hoc test\n",
    "\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "\n",
    "print(\"\\n\\nA post-hoc test\\n\\n\")\n",
    "\n",
    "all_scores = np.concatenate([control_group_scores, experimental_group_scores])\n",
    "group_labels = ['Control'] * len(control_group_scores) + ['Experimental'] * len(experimental_group_scores)\n",
    "\n",
    "# Perform Tukey's HSD test for post-hoc analysis\n",
    "result = pairwise_tukeyhsd(all_scores, group_labels, alpha=0.05)\n",
    "\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol 12\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data (replace with your actual data)\n",
    "data = {\n",
    "    'Store': ['A'] * 30 + ['B'] * 30 + ['C'] * 30,\n",
    "    'Sales': [200, 210, 220, 190, 205, 215]  # Daily sales for each store over 30 days\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform a one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(df[df['Store'] == 'A']['Sales'],\n",
    "                                      df[df['Store'] == 'B']['Sales'],\n",
    "                                      df[df['Store'] == 'C']['Sales'])\n",
    "\n",
    "# Report the results\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "alpha = 0.05  # Set your significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference in daily sales between the three stores.\")\n",
    "    # Perform post-hoc tests (e.g., Tukey's HSD) to determine which stores differ significantly\n",
    "else:\n",
    "    print(\"There is no significant difference in daily sales between the three stores.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ((((WRONG ANSWER DON\"T CHECK IT))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol 10 (answer is not coming ((((WRONG ANSWER DON\"T CHECK IT)))))\n",
    "\n",
    "# # #Data of 30 employees to one of its programs\n",
    "# # p1=np.random.normal(loc=2,scale=2,size=30).round(2)\n",
    "# # p2=np.random.normal(loc=2,scale=2,size=30).round(2)\n",
    "# # p3=np.random.normal(loc=2,scale=2,size=30).round(2)\n",
    "\n",
    "# # #time is never be in the -ve\n",
    "# # p1=p1-min(p1)+5\n",
    "# # p2=p2-min(p2)+5\n",
    "# # p3=p3-min(p3)+5\n",
    "\n",
    "# # df=pd.DataFrame({\"p1\":p1,\"p2\":p2,\"p3\":p3})\n",
    "\n",
    "# import pandas as pd\n",
    "# import scipy.stats as stats\n",
    "\n",
    "# # Sample data (replace with your actual data)\n",
    "# data = {\n",
    "#     'Software': ['A', 'B', 'C'] * 30,\n",
    "#     'Experience': ['Novice'] * 60 + ['Experienced'] * 30,\n",
    "#     'CompletionTime': [12.3, 13.2, 11.8, 11.2, 13.6, 12.1, 12.9, 14.3, 13.8, 13.2,\n",
    "#                        14.1, 12.4, 11.9, 13.0, 12.6, 13.4, 11.8, 13.3, 12.2, 13.5,\n",
    "#                        12.7, 13.0, 12.3, 13.7, 11.9, 13.8, 12.0, 11.5, 13.2, 12.7,12.3, 13.2, 11.8, 11.2, 13.6, 12.1, 12.9, 14.3, 13.8, 13.2,\n",
    "#                        14.1, 12.4, 11.9, 13.0, 12.6, 13.4, 11.8, 13.3, 12.2, 13.5,\n",
    "#                        12.7, 13.0, 12.3, 13.7, 11.9, 13.8, 12.0, 11.5, 13.2, 12.7 ,12.3, 13.2, 11.8, 11.2, 13.6, 12.1, 12.9, 14.3, 13.8, 13.2,\n",
    "#                        14.1, 12.4, 11.9, 13.0, 12.6, 13.4, 11.8, 13.3, 12.2, 13.5,\n",
    "#                        12.7, 13.0, 12.3, 13.7, 11.9, 13.8, 12.0, 11.5, 13.2, 12.7                   \n",
    "#                        ]\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Perform two-way ANOVA\n",
    "# formula = 'CompletionTime ~ C(Software) + C(Experience) + C(Software):C(Experience)'\n",
    "# model = stats.ols(formula, data=df).fit()\n",
    "# anova_table = stats.anova_lm(model, typ=2)\n",
    "\n",
    "# # Report the results\n",
    "# print(anova_table)\n",
    "\n",
    "# # Interpret the results\n",
    "# alpha = 0.05  # Set your significance level\n",
    "\n",
    "# # Check for main effects and interaction effects\n",
    "# if anova_table['PR(>F)']['C(Software)'] < alpha:\n",
    "#     print(\"There is a significant main effect of software programs on completion time.\")\n",
    "# else:\n",
    "#     print(\"There is no significant main effect of software programs on completion time.\")\n",
    "\n",
    "# if anova_table['PR(>F)']['C(Experience)'] < alpha:\n",
    "#     print(\"There is a significant main effect of employee experience on completion time.\")\n",
    "# else:\n",
    "#     print(\"There is no significant main effect of employee experience on completion time.\")\n",
    "\n",
    "# if anova_table['PR(>F)']['C(Software):C(Experience)'] < alpha:\n",
    "#     print(\"There is a significant interaction effect between software programs and employee experience on completion time.\")\n",
    "# else:\n",
    "#     print(\"There is no significant interaction effect between software programs and employee experience on completion time.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
