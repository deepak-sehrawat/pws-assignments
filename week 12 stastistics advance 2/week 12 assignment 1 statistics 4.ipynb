{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imorting of the important libraies \n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol 1 \n",
    "\n",
    "# A t-test and a z-test are both statistical hypothesis tests used to make inferences about population parameters based on sample data. However, they are suited for different situations and have different requirements:\n",
    "\n",
    "# T-Test:\n",
    "\n",
    "    # When to use: \n",
    "        # T-tests are used when the sample size is relatively small (typically less than 30) and the population standard deviation is unknown.\n",
    "\n",
    "    # Example Scenario: \n",
    "        # Imagine you are conducting a study to compare the average test scores of two different groups of students (Group A and Group B) to determine if there is a significant difference between their performances. Since you are dealing with sample sizes that are not large, and you do not know the population standard deviation for test scores, you would use a t-test to analyze the data.\n",
    "\n",
    "# Z-Test:\n",
    "\n",
    "    # When to use: \n",
    "        #  Z-tests are appropriate when the sample size is large (typically greater than 30) or when you have complete knowledge of the population parameters, including the population standard deviation.\n",
    "\n",
    "    # Example Scenario: \n",
    "        #  Suppose you work for a company and want to determine if the average age of your employees is significantly different from the national average age. In this case, if you have a large enough sample (e.g., more than 30 employees) or if you have access to the population standard deviation for ages, you could use a z-test to make the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol 2\n",
    "# one-tailed\n",
    "    # A one-tailed test involves a specific directional hypothesis, focusing on either the left or right tail of a probability distribution. It aims to detect an effect in one direction, making it suitable when researchers have a prior expectation.\n",
    "    # One-tailed tests offer higher power in detecting specific effects.\n",
    "\n",
    "# two-tailed\n",
    "    # A two-tailed test employs a non-directional hypothesis, examining both tails of the distribution to identify any significant difference. It is used when researchers are open to detecting effects in either direction. \n",
    "    # two-tailed tests are more suitable for exploratory analyses or when no directional expectation exists.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol 3\n",
    "# Type 1 Error (False Positive):\n",
    "\n",
    "    # Definition: \n",
    "        # A Type 1 error occurs when a researcher incorrectly rejects a true null hypothesis. In other words, it's a false positive, indicating that there's an effect or difference when there isn't one.\n",
    "\n",
    "    # Example : \n",
    "        # Imagine a pharmaceutical company testing a new drug's effectiveness. They set up a null hypothesis that the drug has no side effects. If, in reality, the drug is safe (the null hypothesis is true), but the statistical test falsely suggests that it has side effects, this is a Type 1 error. It could lead to unnecessary concerns, additional testing, or even the withdrawal of a beneficial drug.\n",
    "\n",
    "# Type 2 Error (False Negative):\n",
    "\n",
    "#     Definition:\n",
    "        # A Type 2 error occurs when a researcher fails to reject a false null hypothesis. In this case, it's a false negative, implying that no effect or difference is detected when there actually is one.\n",
    "\n",
    "#     Example :\n",
    "        # Consider a quality control scenario where a factory wants to ensure that no defective products are shipped. The null hypothesis states that the product is defect-free. If, in reality, there are defects (the null hypothesis is false), but the quality control test fails to detect them, this is a Type 2 error. Defective products might be shipped to customers, leading to potential recalls or customer dissatisfaction.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol 4\n",
    "# Bayes's theorem is a probabilistic tool for updating our beliefs based on new evidence. It's widely used in fields like medicine and machine learning. Here's an example:\n",
    "\n",
    "# Medical Diagnosis Example:\n",
    "\n",
    "# Imagine a medical test for a rare disease that is 99% accurate. Let's say the disease affects 1% of the population. If a person tests positive P(T), you might think they have a 99% chance of having the disease. However, Bayes's theorem helps us refine this.\n",
    "\n",
    "# (P(D)) is the prior probability of having the disease (1%).\n",
    "# (P(T|D)) is the probability of testing positive if you have the disease (99%).\n",
    "# (P(\\neg D)) is the probability of not having the disease (complement of (P(D)), 99%).\n",
    "# (P(T|\\neg D)) is the probability of testing positive if you don't have the disease (1%).\n",
    "\n",
    "# Using Bayes's theorem, we can calculate (P(D|T)), the updated probability of having the disease given a positive test result:\n",
    "\n",
    "# [P(D|T) ={P(D) * P(T|D)}/{P(T)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol 5\n",
    "\n",
    "# Definition:\n",
    "    # A confidence interval is a statistical range that estimates the likely range of values for a population parameter (e.g., mean, proportion) with a specified level of confidence. It provides a measure of uncertainty associated with sample data.\n",
    "\n",
    "# Example: \n",
    "    # Suppose you want to estimate the average age of a population. You collect a random sample of 100 individuals and find their average age to be 40 years with a standard deviation of 5 years. Using a 95% confidence level and a Z-table (for large samples), you calculate the margin of error to be 1.96 (for 95% confidence). Thus, the 95% confidence interval for the average age is [37.04, 42.96] years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol 6\n",
    "# Certainly, let's use Bayes' Theorem to calculate the probability of an event given prior knowledge and new evidence in a sample problem:\n",
    "\n",
    "# **Sample Problem: Medical Diagnosis**\n",
    "\n",
    "# Suppose there's a rare disease (D) that affects 1% of the population. A diagnostic test (T) for this disease is known to be 90% accurate when it comes to true positives (detecting the disease when it's present) and 95% accurate in true negatives (correctly identifying the absence of the disease). We want to calculate the probability that a person has the disease if they test positive (\\(P(D|T)\\)).\n",
    "\n",
    "# Given:\n",
    "# - \\(P(D)\\): The prior probability of having the disease (0.01 or 1%).\n",
    "# - \\(P(T|D)\\): The probability of testing positive if you have the disease (0.90 or 90%).\n",
    "# - \\(P(\\neg D)\\): The probability of not having the disease (0.99 or 99%, the complement of (P(D))).\n",
    "# - \\(P(T|\\neg D)\\): The probability of testing positive if you don't have the disease (0.05 or 5%).\n",
    "\n",
    "# Using Bayes' Theorem:\n",
    "\n",
    "# [P(D|T) = {P(T|D)*P(D)}/{P(T)}]\n",
    "\n",
    "# First, calculate (P(T)) using the law of total probability:\n",
    "\n",
    "# [P(T) = P(T|D) * P(D) + P(T|\\neg D)*P(\\neg D)\\]\n",
    "\n",
    "# Now, plug in the values:\n",
    "\n",
    "# [P(T) = (0.90 * 0.01) + (0.05 * 0.99) = 0.0145 + 0.0495 = 0.064]\n",
    "\n",
    "# Finally, calculate (P(D|T)):\n",
    "\n",
    "# [P(D|T) = {0.90 * 0.01}/{0.064} ≈ 0.1406]\n",
    "\n",
    "# So, if a person tests positive for the disease, the probability that they actually have the disease is approximately 14.06%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the range for the mean of the 95% confidence level is b/w 48.04 - 51.96\n"
     ]
    }
   ],
   "source": [
    "# sol 7\n",
    "sd=5\n",
    "x_mean=50\n",
    "ci=95\n",
    "# n is not given  (sample size is not given)\n",
    "si=1-(ci/100)\n",
    "alfa=1-si/2\n",
    "z_value=stats.norm.ppf(alfa)\n",
    "z_value=round(z_value,3)\n",
    "uper_range=x_mean+z_value\n",
    "lower_range=x_mean-z_value\n",
    "print(\"the range for the mean of the 95% confidence level is b/w\",lower_range,\"-\",uper_range)\n",
    "\n",
    "# interpretation\n",
    "# the calculated interval is [48.12, 51.88], it means that you can be 95% confident that the true population mean lies within this range based on the sample data. \n",
    "# The larger the sample size, the narrower the confidence interval, indicating more precise estimation of the population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.79981992270027"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sol 8 \n",
    "# The margin of error (MOE) in a confidence interval measures the range around a point estimate (e.g., sample mean) used to estimate a population parameter with a specified level of confidence. It is calculated using the formula:\n",
    "\n",
    "# text{MOE} = Z * {sigma}/sqrt{n}\n",
    "\n",
    "# Here's how sample size affects MOE:\n",
    "\n",
    "# 1. **Inverse Relationship**: Sample size (n) and MOE have an inverse relationship. As (n) increases, MOE decreases. Larger samples result in smaller MOEs, indicating more precise estimates.\n",
    "\n",
    "# 2. **Increased Precision**: Larger samples provide more information about the population, reducing the variability in the sample mean. This leads to narrower confidence intervals and more confidence in the estimate's accuracy.\n",
    "\n",
    "# For example, in a political poll:\n",
    "\n",
    "# - Scenario 1 (Small Sample Size):\n",
    "#   n_1 = 200\n",
    "#   - MOE = 0.05 (After the calculation)\n",
    "#   - Indicates that the estimate can vary by up to 5% from the true proportion with 95% confidence.\n",
    "\n",
    "# - Scenario 2 (Large Sample Size):\n",
    "#   - n_2 = 2,000\n",
    "#   - MOE = 0.02 (After the calculation)\n",
    "#   - Indicates a more precise estimate, with a variation of up to 2% from the true proportion with 95% confidence.\n",
    "\n",
    "# Larger sample sizes yield more accurate and narrower confidence intervals, reducing uncertainty in the estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# sol 9\n",
    "x_point=75\n",
    "u_mean=70\n",
    "sd=5\n",
    "z_score=(x_point-u_mean)/sd\n",
    "print (z_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we reject null hypothies--- the outcome is  the drug helps in loss the weight u_mean ≠ 0\n"
     ]
    }
   ],
   "source": [
    "# sol 10\n",
    "from scipy.stats import t\n",
    "n=50\n",
    "x_mean=6\n",
    "sd=2.5\n",
    "cl=95\n",
    "u_mean=0   #(not given so let it 2 pound loss)\n",
    "h0=\"the drug not help in loss the weight u_mean=0\"\n",
    "h1=\"the drug helps in loss the weight u_mean ≠ 0\"\n",
    "\n",
    "sl=1-(cl/100)\n",
    "alfa=1-(si/2)\n",
    "# critical value \n",
    "cv=stats.t.ppf(alfa,n-1)\n",
    "\n",
    "t_score=x_mean-u_mean/(sd/math.sqrt(n)) \n",
    "# t_score=abs(t_score)\n",
    "\n",
    "if t_score>cv:\n",
    "    print (\"we reject null hypothies--- the outcome is \",h1)\n",
    "else:\n",
    "    print (\"we fail to reject null hypothies--- the outcome is \",h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true proportion of people who are satisfied with their job are from 323.0 to 327.0 persons\n"
     ]
    }
   ],
   "source": [
    "# sol 11\n",
    "n=500\n",
    "satisfied_persons=500*65/100\n",
    "ci=95\n",
    "sl=1-ci/100\n",
    "alfa=1-si/2 #for two tail\n",
    "z_value=stats.norm.ppf(alfa)\n",
    "uper_range=satisfied_persons+z_value.round()\n",
    "lower_range=satisfied_persons-z_value.round()\n",
    "print(f\"true proportion of people who are satisfied with their job are from {lower_range} to {uper_range} persons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol 12 \n",
    "# how we can perforn the t-test without the degre of freedom for the degree of freedom we need the n (sample size that is not given in the question)\n",
    "# (or may be i dont know the  solution plz help me in this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the range for the mean of the 90% confidence level is b/w 58.139 - 61.861\n"
     ]
    }
   ],
   "source": [
    "# sol 13\n",
    "\n",
    "sd=8\n",
    "u_mean=60\n",
    "n=50\n",
    "# n is not given  (sample size is not given)\n",
    "si=0.1\n",
    "alfa=1-si/2\n",
    "z_value=stats.norm.ppf(alfa)\n",
    "z_value=round(z_value,3)\n",
    "standerd_error=z_value*sd/math.sqrt(50)\n",
    "uper_range=u_mean+round(standerd_error,3)\n",
    "lower_range=u_mean-round(standerd_error,3)\n",
    "print(\"the range for the mean of the 90% confidence level is b/w\",lower_range,\"-\",uper_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the critical point is 1.6991\n",
      "the t_score is 27.386127875258307\n",
      "reject the null hypothesis the outcome is --  there is an effect in reaction time  where u_mean ≠ 0 \n"
     ]
    }
   ],
   "source": [
    "# sol 14\n",
    "x_mean=0.25\n",
    "sd=0.05\n",
    "n=30\n",
    "cl=90\n",
    "h0=\"no effect in reaction time where u_mean = 0\"\n",
    "h1=\"there is an effect in reaction time  where u_mean ≠ 0 \"\n",
    "u_mean=0 #(let the umean accourding to the h0 where there is not any effect on reaction time)\n",
    "si=1-(cl/100)\n",
    "alfa=1-si/2\n",
    "critical_point=stats.t.ppf(alfa,n-1).round(4)\n",
    "print(f\"the critical point is {critical_point}\\nthe t_score is {t}\")\n",
    "t=(x_mean-u_mean)/(sd/math.sqrt(n))\n",
    "if t>critical_point:\n",
    "    print(\"reject the null hypothesis the outcome is -- \",h1)\n",
    "else:\n",
    "    print(\"fail to reject the null hypothisis the outcome is -- \",h0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
